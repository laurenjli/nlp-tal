{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lucem_illud_2020\n",
    "\n",
    "import scipy\n",
    "import sklearn_extra\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "import sklearn.metrics\n",
    "import sklearn.mixture\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "import networkx as nx\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.matutils import kullback_leibler\n",
    "from gensim import models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "\n",
    "from source import helper_functions as hf, cluster_fns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tal_df = hf.load_df('total_trans_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_num</th>\n",
       "      <th>ep_title</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>act_name</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>no_lemma_normalized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>no_lemma_normalized_tokens</th>\n",
       "      <th>five_yr_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.thisamericanlife.org/1/transcript</td>\n",
       "      <td>Act Four: Act Four</td>\n",
       "      <td>This is Your Radio Playhouse. I'm Ira Glass. O...</td>\n",
       "      <td>[[This, is, Your, Radio, Playhouse], [I, 'm, I...</td>\n",
       "      <td>[[radio, playhouse], [m, ira, glass], [ok, rig...</td>\n",
       "      <td>[[radio, playhouse], [be, ira, glass], [okay, ...</td>\n",
       "      <td>[This, is, Your, Radio, Playhouse, I, 'm, Ira,...</td>\n",
       "      <td>[radio, playhouse, be, ira, glass, okay, right...</td>\n",
       "      <td>[radio, playhouse, m, ira, glass, ok, right, r...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.thisamericanlife.org/1/transcript</td>\n",
       "      <td>Act Three: Act Three</td>\n",
       "      <td>Well, next on our little playhouse stage, we h...</td>\n",
       "      <td>[[Well, next, on, our, little, playhouse, stag...</td>\n",
       "      <td>[[little, playhouse, stage, mr, lawrence, steg...</td>\n",
       "      <td>[[little, playhouse, stage, mr, lawrence, steg...</td>\n",
       "      <td>[Well, next, on, our, little, playhouse, stage...</td>\n",
       "      <td>[little, playhouse, stage, mr, lawrence, stege...</td>\n",
       "      <td>[little, playhouse, stage, mr, lawrence, stege...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.thisamericanlife.org/1/transcript</td>\n",
       "      <td>Act Two: Act Two</td>\n",
       "      <td>Good morning. Glass, Jacobson &amp; Associates.Hey...</td>\n",
       "      <td>[[Good, morning], [Glass, Jacobson, Associates...</td>\n",
       "      <td>[[good, morning], [glass, jacobson, associates...</td>\n",
       "      <td>[[good, morning], [glass, jacobson, associate]...</td>\n",
       "      <td>[Good, morning, Glass, Jacobson, Associates, H...</td>\n",
       "      <td>[good, morning, glass, jacobson, associate, he...</td>\n",
       "      <td>[good, morning, glass, jacobson, associates, h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.thisamericanlife.org/1/transcript</td>\n",
       "      <td>Act One: Act One</td>\n",
       "      <td>All right, Your Radio Playhouse. All right. I'...</td>\n",
       "      <td>[[All, right, Your, Radio, Playhouse], [All, r...</td>\n",
       "      <td>[[right, radio, playhouse], [right], [m, makin...</td>\n",
       "      <td>[[right, radio, playhouse], [right], [be, make...</td>\n",
       "      <td>[All, right, Your, Radio, Playhouse, All, righ...</td>\n",
       "      <td>[right, radio, playhouse, right, be, make, eye...</td>\n",
       "      <td>[right, radio, playhouse, right, m, making, ey...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.thisamericanlife.org/1/transcript</td>\n",
       "      <td>Prologue</td>\n",
       "      <td>Joe Franklin?I'm ready.It's Ira Glass here.Oh,...</td>\n",
       "      <td>[[Joe, Franklin?I'm, ready], [It, 's, Ira, Gla...</td>\n",
       "      <td>[[joe, franklin?i'm, ready], [ira, glass], [oh...</td>\n",
       "      <td>[[joe, franklin?i'm, ready], [ira, glass], [oh...</td>\n",
       "      <td>[Joe, Franklin?I'm, ready, It, 's, Ira, Glass,...</td>\n",
       "      <td>[joe, franklin?i'm, ready, ira, glass, oh, emc...</td>\n",
       "      <td>[joe, franklin?i'm, ready, ira, glass, oh, emc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ep_num        ep_title  year  \\\n",
       "0       1  New Beginnings  1995   \n",
       "1       1  New Beginnings  1995   \n",
       "2       1  New Beginnings  1995   \n",
       "3       1  New Beginnings  1995   \n",
       "4       1  New Beginnings  1995   \n",
       "\n",
       "                                             url              act_name  \\\n",
       "0  https://www.thisamericanlife.org/1/transcript    Act Four: Act Four   \n",
       "1  https://www.thisamericanlife.org/1/transcript  Act Three: Act Three   \n",
       "2  https://www.thisamericanlife.org/1/transcript      Act Two: Act Two   \n",
       "3  https://www.thisamericanlife.org/1/transcript      Act One: Act One   \n",
       "4  https://www.thisamericanlife.org/1/transcript              Prologue   \n",
       "\n",
       "                                                text  \\\n",
       "0  This is Your Radio Playhouse. I'm Ira Glass. O...   \n",
       "1  Well, next on our little playhouse stage, we h...   \n",
       "2  Good morning. Glass, Jacobson & Associates.Hey...   \n",
       "3  All right, Your Radio Playhouse. All right. I'...   \n",
       "4  Joe Franklin?I'm ready.It's Ira Glass here.Oh,...   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [[This, is, Your, Radio, Playhouse], [I, 'm, I...   \n",
       "1  [[Well, next, on, our, little, playhouse, stag...   \n",
       "2  [[Good, morning], [Glass, Jacobson, Associates...   \n",
       "3  [[All, right, Your, Radio, Playhouse], [All, r...   \n",
       "4  [[Joe, Franklin?I'm, ready], [It, 's, Ira, Gla...   \n",
       "\n",
       "                           no_lemma_normalized_sents  \\\n",
       "0  [[radio, playhouse], [m, ira, glass], [ok, rig...   \n",
       "1  [[little, playhouse, stage, mr, lawrence, steg...   \n",
       "2  [[good, morning], [glass, jacobson, associates...   \n",
       "3  [[right, radio, playhouse], [right], [m, makin...   \n",
       "4  [[joe, franklin?i'm, ready], [ira, glass], [oh...   \n",
       "\n",
       "                                    normalized_sents  \\\n",
       "0  [[radio, playhouse], [be, ira, glass], [okay, ...   \n",
       "1  [[little, playhouse, stage, mr, lawrence, steg...   \n",
       "2  [[good, morning], [glass, jacobson, associate]...   \n",
       "3  [[right, radio, playhouse], [right], [be, make...   \n",
       "4  [[joe, franklin?i'm, ready], [ira, glass], [oh...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [This, is, Your, Radio, Playhouse, I, 'm, Ira,...   \n",
       "1  [Well, next, on, our, little, playhouse, stage...   \n",
       "2  [Good, morning, Glass, Jacobson, Associates, H...   \n",
       "3  [All, right, Your, Radio, Playhouse, All, righ...   \n",
       "4  [Joe, Franklin?I'm, ready, It, 's, Ira, Glass,...   \n",
       "\n",
       "                                   normalized_tokens  \\\n",
       "0  [radio, playhouse, be, ira, glass, okay, right...   \n",
       "1  [little, playhouse, stage, mr, lawrence, stege...   \n",
       "2  [good, morning, glass, jacobson, associate, he...   \n",
       "3  [right, radio, playhouse, right, be, make, eye...   \n",
       "4  [joe, franklin?i'm, ready, ira, glass, oh, emc...   \n",
       "\n",
       "                          no_lemma_normalized_tokens  five_yr_group  \n",
       "0  [radio, playhouse, m, ira, glass, ok, right, r...            0.0  \n",
       "1  [little, playhouse, stage, mr, lawrence, stege...            0.0  \n",
       "2  [good, morning, glass, jacobson, associates, h...            0.0  \n",
       "3  [right, radio, playhouse, right, m, making, ey...            0.0  \n",
       "4  [joe, franklin?i'm, ready, ira, glass, oh, emc...            0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tal_df = hf.split_five_years(tal_df)\n",
    "tal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_yr_group</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>no_lemma_normalized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>no_lemma_normalized_tokens</th>\n",
       "      <th>reduced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>This is Your Radio Playhouse. I'm Ira Glass. O...</td>\n",
       "      <td>[[This, is, Your, Radio, Playhouse], [I, 'm, I...</td>\n",
       "      <td>[[radio, playhouse], [m, ira, glass], [ok, rig...</td>\n",
       "      <td>[[radio, playhouse], [be, ira, glass], [okay, ...</td>\n",
       "      <td>[This, is, Your, Radio, Playhouse, I, 'm, Ira,...</td>\n",
       "      <td>[radio, playhouse, be, ira, glass, okay, right...</td>\n",
       "      <td>[radio, playhouse, m, ira, glass, ok, right, r...</td>\n",
       "      <td>[playhouse, ryder, graterford, graterford, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>It's This American Life. I'm Ira Glass. Most w...</td>\n",
       "      <td>[[It, 's, This, American, Life], [I, 'm, Ira, ...</td>\n",
       "      <td>[[american, life], [m, ira, glass], [weeks, pr...</td>\n",
       "      <td>[[american, life], [be, ira, glass], [week, pr...</td>\n",
       "      <td>[It, 's, This, American, Life, I, 'm, Ira, Gla...</td>\n",
       "      <td>[american, life, be, ira, glass, week, program...</td>\n",
       "      <td>[american, life, m, ira, glass, weeks, program...</td>\n",
       "      <td>[redding, lac, meister, bieber, bieber, bieber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Act Three, Babies Buying Babies. Elna Baker a...</td>\n",
       "      <td>[[Act, Three, Babies, Buying, Babies], [Elna, ...</td>\n",
       "      <td>[[act, babies, buying, babies], [elna, baker, ...</td>\n",
       "      <td>[[act, baby, buy, baby], [elna, baker, want, a...</td>\n",
       "      <td>[Act, Three, Babies, Buying, Babies, Elna, Bak...</td>\n",
       "      <td>[act, baby, buy, baby, elna, baker, want, actr...</td>\n",
       "      <td>[act, babies, buying, babies, elna, baker, wan...</td>\n",
       "      <td>[elna, elna, middleton, middleton, middleton, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Act Four, The Deepest, Darkest Open Secret. Mo...</td>\n",
       "      <td>[[Act, Four, The, Deepest, Darkest, Open, Secr...</td>\n",
       "      <td>[[act, deepest, darkest, open, secret], [years...</td>\n",
       "      <td>[[act, deep, dark, open, secret], [year, ago, ...</td>\n",
       "      <td>[Act, Four, The, Deepest, Darkest, Open, Secre...</td>\n",
       "      <td>[act, deep, dark, open, secret, year, ago, sol...</td>\n",
       "      <td>[act, deepest, darkest, open, secret, years, a...</td>\n",
       "      <td>[sonari, sonari, sonari, sonari, sonari, sonar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   five_yr_group                                               text  \\\n",
       "0            0.0  This is Your Radio Playhouse. I'm Ira Glass. O...   \n",
       "1            1.0  It's This American Life. I'm Ira Glass. Most w...   \n",
       "2            2.0   Act Three, Babies Buying Babies. Elna Baker a...   \n",
       "3            3.0  Act Four, The Deepest, Darkest Open Secret. Mo...   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [[This, is, Your, Radio, Playhouse], [I, 'm, I...   \n",
       "1  [[It, 's, This, American, Life], [I, 'm, Ira, ...   \n",
       "2  [[Act, Three, Babies, Buying, Babies], [Elna, ...   \n",
       "3  [[Act, Four, The, Deepest, Darkest, Open, Secr...   \n",
       "\n",
       "                           no_lemma_normalized_sents  \\\n",
       "0  [[radio, playhouse], [m, ira, glass], [ok, rig...   \n",
       "1  [[american, life], [m, ira, glass], [weeks, pr...   \n",
       "2  [[act, babies, buying, babies], [elna, baker, ...   \n",
       "3  [[act, deepest, darkest, open, secret], [years...   \n",
       "\n",
       "                                    normalized_sents  \\\n",
       "0  [[radio, playhouse], [be, ira, glass], [okay, ...   \n",
       "1  [[american, life], [be, ira, glass], [week, pr...   \n",
       "2  [[act, baby, buy, baby], [elna, baker, want, a...   \n",
       "3  [[act, deep, dark, open, secret], [year, ago, ...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [This, is, Your, Radio, Playhouse, I, 'm, Ira,...   \n",
       "1  [It, 's, This, American, Life, I, 'm, Ira, Gla...   \n",
       "2  [Act, Three, Babies, Buying, Babies, Elna, Bak...   \n",
       "3  [Act, Four, The, Deepest, Darkest, Open, Secre...   \n",
       "\n",
       "                                   normalized_tokens  \\\n",
       "0  [radio, playhouse, be, ira, glass, okay, right...   \n",
       "1  [american, life, be, ira, glass, week, program...   \n",
       "2  [act, baby, buy, baby, elna, baker, want, actr...   \n",
       "3  [act, deep, dark, open, secret, year, ago, sol...   \n",
       "\n",
       "                          no_lemma_normalized_tokens  \\\n",
       "0  [radio, playhouse, m, ira, glass, ok, right, r...   \n",
       "1  [american, life, m, ira, glass, weeks, program...   \n",
       "2  [act, babies, buying, babies, elna, baker, wan...   \n",
       "3  [act, deepest, darkest, open, secret, years, a...   \n",
       "\n",
       "                                      reduced_tokens  \n",
       "0  [playhouse, ryder, graterford, graterford, gra...  \n",
       "1  [redding, lac, meister, bieber, bieber, bieber...  \n",
       "2  [elna, elna, middleton, middleton, middleton, ...  \n",
       "3  [sonari, sonari, sonari, sonari, sonari, sonar...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_period = hf.agg_text(tal_df, 'five_yr_group', False)\n",
    "by_period.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Topics by Year & Apply to 5 Years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prologues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get topics from prologues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_title</th>\n",
       "      <th>ep_num</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>no_lemma_normalized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>no_lemma_normalized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Better Mousetrap</td>\n",
       "      <td>311</td>\n",
       "      <td>2006</td>\n",
       "      <td>https://www.thisamericanlife.org/311/transcript</td>\n",
       "      <td>Andy's grandfather ran the business. Then his ...</td>\n",
       "      <td>[[Andy, 's, grandfather, ran, the, business], ...</td>\n",
       "      <td>[[andy, grandfather, ran, business], [father, ...</td>\n",
       "      <td>[[andy, grandfather, run, business], [father, ...</td>\n",
       "      <td>[Andy, 's, grandfather, ran, the, business, Th...</td>\n",
       "      <td>[andy, grandfather, run, business, father, run...</td>\n",
       "      <td>[andy, grandfather, ran, business, father, ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Better Mousetrap 2008</td>\n",
       "      <td>366</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://www.thisamericanlife.org/366/transcript</td>\n",
       "      <td>Act Four, \"The Not-For-Profit Motive.\" In resp...</td>\n",
       "      <td>[[Act, Four, The, Not, For, Profit, Motive], [...</td>\n",
       "      <td>[[act, profit, motive], [], [responding, curre...</td>\n",
       "      <td>[[act, profit, motive], [], [respond, current,...</td>\n",
       "      <td>[Act, Four, The, Not, For, Profit, Motive, In,...</td>\n",
       "      <td>[act, profit, motive, respond, current, financ...</td>\n",
       "      <td>[act, profit, motive, responding, current, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Front</td>\n",
       "      <td>540</td>\n",
       "      <td>2014</td>\n",
       "      <td>https://www.thisamericanlife.org/540/transcript</td>\n",
       "      <td>Act One, WTF, ATF? So a funny thing happened a...</td>\n",
       "      <td>[[Act, One, WTF, ATF], [So, a, funny, thing, h...</td>\n",
       "      <td>[[act, wtf, atf], [funny, thing, happened, joh...</td>\n",
       "      <td>[[act, wtf, atf], [funny, thing, happen, john,...</td>\n",
       "      <td>[Act, One, WTF, ATF, So, a, funny, thing, happ...</td>\n",
       "      <td>[act, wtf, atf, funny, thing, happen, john, ra...</td>\n",
       "      <td>[act, wtf, atf, funny, thing, happened, john, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A House Divided</td>\n",
       "      <td>439</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.thisamericanlife.org/439/transcript</td>\n",
       "      <td>It's This American Life. I'm Ira Glass. Each w...</td>\n",
       "      <td>[[It, 's, This, American, Life], [I, 'm, Ira, ...</td>\n",
       "      <td>[[american, life], [m, ira, glass], [week, cou...</td>\n",
       "      <td>[[american, life], [be, ira, glass], [week, co...</td>\n",
       "      <td>[It, 's, This, American, Life, I, 'm, Ira, Gla...</td>\n",
       "      <td>[american, life, be, ira, glass, week, course,...</td>\n",
       "      <td>[american, life, m, ira, glass, week, course, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Little Bit of Knowledge</td>\n",
       "      <td>293</td>\n",
       "      <td>2005</td>\n",
       "      <td>https://www.thisamericanlife.org/293/transcript</td>\n",
       "      <td>It's This American Life. I'm Ira Glass. Each w...</td>\n",
       "      <td>[[It, 's, This, American, Life], [I, 'm, Ira, ...</td>\n",
       "      <td>[[american, life], [m, ira, glass], [week, pro...</td>\n",
       "      <td>[[american, life], [be, ira, glass], [week, pr...</td>\n",
       "      <td>[It, 's, This, American, Life, I, 'm, Ira, Gla...</td>\n",
       "      <td>[american, life, be, ira, glass, week, program...</td>\n",
       "      <td>[american, life, m, ira, glass, week, program,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ep_title  ep_num  year  \\\n",
       "0         A Better Mousetrap     311  2006   \n",
       "1    A Better Mousetrap 2008     366  2008   \n",
       "2                    A Front     540  2014   \n",
       "3            A House Divided     439  2011   \n",
       "4  A Little Bit of Knowledge     293  2005   \n",
       "\n",
       "                                               url  \\\n",
       "0  https://www.thisamericanlife.org/311/transcript   \n",
       "1  https://www.thisamericanlife.org/366/transcript   \n",
       "2  https://www.thisamericanlife.org/540/transcript   \n",
       "3  https://www.thisamericanlife.org/439/transcript   \n",
       "4  https://www.thisamericanlife.org/293/transcript   \n",
       "\n",
       "                                                text  \\\n",
       "0  Andy's grandfather ran the business. Then his ...   \n",
       "1  Act Four, \"The Not-For-Profit Motive.\" In resp...   \n",
       "2  Act One, WTF, ATF? So a funny thing happened a...   \n",
       "3  It's This American Life. I'm Ira Glass. Each w...   \n",
       "4  It's This American Life. I'm Ira Glass. Each w...   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [[Andy, 's, grandfather, ran, the, business], ...   \n",
       "1  [[Act, Four, The, Not, For, Profit, Motive], [...   \n",
       "2  [[Act, One, WTF, ATF], [So, a, funny, thing, h...   \n",
       "3  [[It, 's, This, American, Life], [I, 'm, Ira, ...   \n",
       "4  [[It, 's, This, American, Life], [I, 'm, Ira, ...   \n",
       "\n",
       "                           no_lemma_normalized_sents  \\\n",
       "0  [[andy, grandfather, ran, business], [father, ...   \n",
       "1  [[act, profit, motive], [], [responding, curre...   \n",
       "2  [[act, wtf, atf], [funny, thing, happened, joh...   \n",
       "3  [[american, life], [m, ira, glass], [week, cou...   \n",
       "4  [[american, life], [m, ira, glass], [week, pro...   \n",
       "\n",
       "                                    normalized_sents  \\\n",
       "0  [[andy, grandfather, run, business], [father, ...   \n",
       "1  [[act, profit, motive], [], [respond, current,...   \n",
       "2  [[act, wtf, atf], [funny, thing, happen, john,...   \n",
       "3  [[american, life], [be, ira, glass], [week, co...   \n",
       "4  [[american, life], [be, ira, glass], [week, pr...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Andy, 's, grandfather, ran, the, business, Th...   \n",
       "1  [Act, Four, The, Not, For, Profit, Motive, In,...   \n",
       "2  [Act, One, WTF, ATF, So, a, funny, thing, happ...   \n",
       "3  [It, 's, This, American, Life, I, 'm, Ira, Gla...   \n",
       "4  [It, 's, This, American, Life, I, 'm, Ira, Gla...   \n",
       "\n",
       "                                   normalized_tokens  \\\n",
       "0  [andy, grandfather, run, business, father, run...   \n",
       "1  [act, profit, motive, respond, current, financ...   \n",
       "2  [act, wtf, atf, funny, thing, happen, john, ra...   \n",
       "3  [american, life, be, ira, glass, week, course,...   \n",
       "4  [american, life, be, ira, glass, week, program...   \n",
       "\n",
       "                          no_lemma_normalized_tokens  \n",
       "0  [andy, grandfather, ran, business, father, ran...  \n",
       "1  [act, profit, motive, responding, current, fin...  \n",
       "2  [act, wtf, atf, funny, thing, happened, john, ...  \n",
       "3  [american, life, m, ira, glass, week, course, ...  \n",
       "4  [american, life, m, ira, glass, week, program,...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics from episodes\n",
    "ep_df = hf.agg_text(tal_df, 'ep_title', True)\n",
    "ep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.8\n",
      "[(0, '0.004*\"book\" + 0.003*\"girl\" + 0.003*\"women\"'), (1, '0.007*\"police\" + 0.004*\"state\" + 0.004*\"court\"'), (2, '0.009*\"speaking\" + 0.006*\"president\" + 0.005*\"government\"'), (3, '0.009*\"mother\" + 0.008*\"dad\" + 0.007*\"mom\"')]\n",
      "  Topic_0    Topic_1     Topic_2   Topic_3\n",
      "0    book     police    speaking    mother\n",
      "1    girl      state   president       dad\n",
      "2   women      court  government       mom\n",
      "3     000     father       white    father\n",
      "4    play  christmas       state   parents\n",
      "5  street        war         war      book\n",
      "6    york     mother     spanish       kid\n",
      "7  father        mom       black     white\n",
      "8    song       drug         000     black\n",
      "9  mother       town        town  children\n",
      "\n",
      "0.2 0.8\n",
      "[(0, '0.004*\"women\" + 0.004*\"girl\" + 0.004*\"book\"'), (1, '0.006*\"police\" + 0.005*\"father\" + 0.004*\"christmas\"'), (2, '0.014*\"speaking\" + 0.008*\"spanish\" + 0.004*\"dad\"'), (3, '0.010*\"mother\" + 0.009*\"dad\" + 0.008*\"mom\"'), (4, '0.006*\"state\" + 0.006*\"government\" + 0.005*\"white\"')]\n",
      "  Topic_0    Topic_1   Topic_2   Topic_3     Topic_4\n",
      "0   women     police  speaking    mother       state\n",
      "1    girl     father   spanish       dad  government\n",
      "2    book  christmas       dad       mom       white\n",
      "3    song     mother    father    father   president\n",
      "4    play        mom     black   parents         000\n",
      "5  father      court   brother      book         war\n",
      "6  street       drug      baby       kid        town\n",
      "7   girls        dad     white  children      office\n",
      "8    york    chicken      play     heart       black\n",
      "9  mother      water    mother      girl       party\n",
      "\n",
      "0.2 0.8\n",
      "[(0, '0.004*\"women\" + 0.004*\"song\" + 0.004*\"girl\"'), (1, '0.009*\"police\" + 0.006*\"court\" + 0.005*\"drug\"'), (2, '0.018*\"speaking\" + 0.010*\"spanish\" + 0.004*\"dad\"'), (3, '0.008*\"dad\" + 0.007*\"mother\" + 0.006*\"mom\"'), (4, '0.007*\"state\" + 0.006*\"government\" + 0.006*\"president\"'), (5, '0.010*\"mother\" + 0.008*\"father\" + 0.007*\"mom\"')]\n",
      "   Topic_0 Topic_1     Topic_2  Topic_3     Topic_4    Topic_5\n",
      "0    women  police    speaking      dad       state     mother\n",
      "1     song   court     spanish   mother  government     father\n",
      "2     girl    drug         dad      mom   president        mom\n",
      "3     book     war         war   father       white    parents\n",
      "4     play   state   president     book         000        dad\n",
      "5     york     law       black  parents        town        kid\n",
      "6   street   judge  government    death         war  christmas\n",
      "7  playing   crime      father    black      office       baby\n",
      "8      sex  father         000    sarah       black   children\n",
      "9      men  prison      police    party     company    chicken\n",
      "\n",
      "0.2 0.8\n",
      "[(0, '0.005*\"song\" + 0.004*\"women\" + 0.004*\"play\"'), (1, '0.009*\"police\" + 0.004*\"father\" + 0.003*\"gun\"'), (2, '0.020*\"speaking\" + 0.011*\"spanish\" + 0.005*\"dad\"'), (3, '0.009*\"dad\" + 0.007*\"mother\" + 0.007*\"mom\"'), (4, '0.008*\"war\" + 0.007*\"town\" + 0.006*\"white\"'), (5, '0.011*\"mother\" + 0.009*\"father\" + 0.008*\"mom\"'), (6, '0.007*\"government\" + 0.007*\"state\" + 0.006*\"court\"')]\n",
      "   Topic_0 Topic_1    Topic_2  Topic_3    Topic_4    Topic_5     Topic_6\n",
      "0     song  police   speaking      dad        war     mother  government\n",
      "1    women  father    spanish   mother       town     father       state\n",
      "2     play     gun        dad      mom      white        mom       court\n",
      "3     girl   water     police   father   students        dad         000\n",
      "4     book  street       play  parents      black    parents         law\n",
      "5     york  mother     father     book      state  christmas      office\n",
      "6      sex     mom    brother    death  president        kid   president\n",
      "7  playing    shot         tv    black     church    chicken       white\n",
      "8   father   crime  president    sarah        000       baby       party\n",
      "9   street  middle        000    heart       york   children     company\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 0.2\n",
    "max_df = 0.8\n",
    "new_models = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9\n",
      "[(0, '0.004*\"kids\" + 0.003*\"love\" + 0.002*\"city\"'), (1, '0.003*\"car\" + 0.003*\"mother\" + 0.003*\"father\"'), (2, '0.003*\"country\" + 0.003*\"president\" + 0.002*\"state\"'), (3, '0.005*\"money\" + 0.003*\"speaking\" + 0.003*\"police\"')]\n",
      "  Topic_0 Topic_1     Topic_2   Topic_3\n",
      "0    kids     car     country     money\n",
      "1    love  mother   president  speaking\n",
      "2    city  father       state    police\n",
      "3   white    love       party      kids\n",
      "4    high    kids       money     phone\n",
      "5     job   money        case      case\n",
      "6   money   music  government     woman\n",
      "7   black     mom       white       mom\n",
      "8    guys     god  republican       dad\n",
      "9    read     war         dad      love\n",
      "\n",
      "5 0.9\n",
      "[(0, '0.004*\"kids\" + 0.003*\"city\" + 0.002*\"white\"'), (1, '0.004*\"father\" + 0.003*\"mother\" + 0.003*\"love\"'), (2, '0.003*\"president\" + 0.003*\"country\" + 0.002*\"party\"'), (3, '0.006*\"money\" + 0.003*\"speaking\" + 0.002*\"police\"'), (4, '0.002*\"car\" + 0.002*\"kids\" + 0.002*\"love\"')]\n",
      "  Topic_0 Topic_1     Topic_2   Topic_3    Topic_4\n",
      "0    kids  father   president     money        car\n",
      "1    city  mother     country  speaking       kids\n",
      "2   white    love       party    police       love\n",
      "3   money     car  government      kids        job\n",
      "4   black    kids       money     state  christmas\n",
      "5    high   money        case       000       door\n",
      "6     job     war         dad      case      phone\n",
      "7    love   music        kids     woman      woman\n",
      "8    read     god       state       mom    chicken\n",
      "9    guys     mom  republican    street        dad\n",
      "\n",
      "5 0.9\n",
      "[(0, '0.005*\"kids\" + 0.003*\"white\" + 0.003*\"love\"'), (1, '0.004*\"father\" + 0.003*\"mother\" + 0.003*\"love\"'), (2, '0.003*\"president\" + 0.003*\"dad\" + 0.003*\"party\"'), (3, '0.007*\"money\" + 0.003*\"speaking\" + 0.003*\"police\"'), (4, '0.003*\"car\" + 0.002*\"kids\" + 0.002*\"job\"'), (5, '0.003*\"chicken\" + 0.003*\"speaking\" + 0.002*\"money\"')]\n",
      "  Topic_0 Topic_1     Topic_2     Topic_3 Topic_4    Topic_5\n",
      "0    kids  father   president       money     car    chicken\n",
      "1   white  mother         dad    speaking    kids   speaking\n",
      "2    love    love       party      police     job      money\n",
      "3    city     car     country         000  mother       love\n",
      "4   black    kids  republican        case    case        job\n",
      "5    high   money         mom        kids    town       city\n",
      "6   money     war      mother  government     mom        fbi\n",
      "7    read     god       state     spanish    love       kids\n",
      "8     job     mom        kids       state    door       guys\n",
      "9    guys   music       white      street   phone  christmas\n",
      "\n",
      "5 0.9\n",
      "[(0, '0.005*\"kids\" + 0.003*\"white\" + 0.002*\"love\"'), (1, '0.004*\"father\" + 0.003*\"mother\" + 0.003*\"car\"'), (2, '0.003*\"dad\" + 0.003*\"country\" + 0.003*\"mother\"'), (3, '0.004*\"speaking\" + 0.004*\"police\" + 0.003*\"money\"'), (4, '0.003*\"car\" + 0.002*\"kids\" + 0.002*\"mother\"'), (5, '0.003*\"chicken\" + 0.003*\"speaking\" + 0.002*\"love\"'), (6, '0.006*\"money\" + 0.003*\"government\" + 0.002*\"president\"')]\n",
      "    Topic_0 Topic_1     Topic_2   Topic_3 Topic_4   Topic_5     Topic_6\n",
      "0      kids  father         dad  speaking     car   chicken       money\n",
      "1     white  mother     country    police    kids  speaking  government\n",
      "2      love     car      mother     money  mother      love   president\n",
      "3      high    love   president      kids    love     money        case\n",
      "4      city    kids       party   spanish     mom      city       state\n",
      "5      read   money         mom      case     dad       job         war\n",
      "6       job     mom        kids     phone     job      kids         000\n",
      "7     black     god       money     woman   woman      guys     country\n",
      "8  students     war  republican       mom    door      game       chris\n",
      "9   parents   music       white       job   phone      girl      office\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 5\n",
    "max_df = 0.9\n",
    "new_models2 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models2.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.8\n",
      "[(0, '0.002*\"christmas\" + 0.002*\"white\" + 0.002*\"chicken\"'), (1, '0.004*\"mother\" + 0.004*\"father\" + 0.004*\"dad\"'), (2, '0.003*\"state\" + 0.003*\"government\" + 0.003*\"president\"'), (3, '0.003*\"police\" + 0.002*\"mother\" + 0.002*\"dad\"')]\n",
      "     Topic_0   Topic_1     Topic_2 Topic_3\n",
      "0  christmas    mother       state  police\n",
      "1      white    father  government  mother\n",
      "2    chicken       dad   president     dad\n",
      "3        war       mom    speaking     mom\n",
      "4       book   parents         000  father\n",
      "5      black      book         war    york\n",
      "6        mom     black       white   david\n",
      "7      santa      girl       party  office\n",
      "8     mother       kid      office  street\n",
      "9     middle  children      states    town\n",
      "\n",
      "10 0.8\n",
      "[(0, '0.003*\"christmas\" + 0.002*\"chicken\" + 0.002*\"white\"'), (1, '0.005*\"mother\" + 0.004*\"father\" + 0.004*\"dad\"'), (2, '0.004*\"speaking\" + 0.003*\"president\" + 0.003*\"state\"'), (3, '0.003*\"police\" + 0.002*\"david\" + 0.002*\"mother\"'), (4, '0.003*\"dad\" + 0.003*\"mom\" + 0.002*\"black\"')]\n",
      "     Topic_0  Topic_1     Topic_2   Topic_3   Topic_4\n",
      "0  christmas   mother    speaking    police       dad\n",
      "1    chicken   father   president     david       mom\n",
      "2      white      dad       state    mother     black\n",
      "3      santa      mom  government    father     state\n",
      "4        war  parents         war      york   parents\n",
      "5      water     girl         000  speaking       000\n",
      "6      black     book       white        tv    mother\n",
      "7       book     play       party       mom     white\n",
      "8     middle      kid      states   spanish      book\n",
      "9       york  brother       court   singing  business\n",
      "\n",
      "10 0.8\n",
      "[(0, '0.003*\"christmas\" + 0.003*\"chicken\" + 0.003*\"santa\"'), (1, '0.004*\"mother\" + 0.004*\"father\" + 0.004*\"dad\"'), (2, '0.004*\"state\" + 0.004*\"speaking\" + 0.004*\"president\"'), (3, '0.005*\"police\" + 0.002*\"speaking\" + 0.002*\"black\"'), (4, '0.003*\"black\" + 0.003*\"dad\" + 0.003*\"mom\"'), (5, '0.003*\"mother\" + 0.003*\"father\" + 0.003*\"dad\"')]\n",
      "     Topic_0   Topic_1     Topic_2     Topic_3     Topic_4   Topic_5\n",
      "0  christmas    mother       state      police       black    mother\n",
      "1    chicken    father    speaking    speaking         dad    father\n",
      "2      santa       dad   president       black         mom       dad\n",
      "3        war       mom  government         fbi       white       mom\n",
      "4      white   parents         war       white     parents      baby\n",
      "5       book      girl         000     spanish       state   parents\n",
      "6      black    church       party      office      mother    street\n",
      "7    animals     black      states  department  government      book\n",
      "8     middle      book       white        town         000  children\n",
      "9        fed  speaking  republican        dole      father       000\n",
      "\n",
      "10 0.8\n",
      "[(0, '0.004*\"war\" + 0.004*\"santa\" + 0.003*\"christmas\"'), (1, '0.004*\"mother\" + 0.003*\"father\" + 0.003*\"dad\"'), (2, '0.004*\"state\" + 0.004*\"speaking\" + 0.004*\"president\"'), (3, '0.005*\"police\" + 0.002*\"speaking\" + 0.002*\"spanish\"'), (4, '0.004*\"mom\" + 0.004*\"dad\" + 0.003*\"black\"'), (5, '0.003*\"mother\" + 0.002*\"father\" + 0.002*\"mom\"'), (6, '0.003*\"father\" + 0.003*\"mother\" + 0.003*\"black\"')]\n",
      "      Topic_0  Topic_1     Topic_2     Topic_3  Topic_4   Topic_5   Topic_6\n",
      "0         war   mother       state      police      mom    mother    father\n",
      "1       santa   father    speaking    speaking      dad    father    mother\n",
      "2   christmas      dad   president     spanish    black       mom     black\n",
      "3        iraq      mom  government  department  parents    street       dad\n",
      "4         fed  parents         war       david    white       dad     white\n",
      "5       white     girl         000         joe   mother       000   chicken\n",
      "6         men     book       party         bob   father      baby       kid\n",
      "7  government   church  republican        cops    state      book      drug\n",
      "8      middle      sex       white      office      kid  business   parents\n",
      "9     animals      men      states        dole     book   parents  children\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 10\n",
    "max_df = 0.8\n",
    "new_models3 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models3.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9\n",
      "[(0, '0.005*\"kids\" + 0.003*\"white\" + 0.003*\"black\"'), (1, '0.004*\"dad\" + 0.003*\"mom\" + 0.003*\"love\"'), (2, '0.004*\"money\" + 0.003*\"case\" + 0.003*\"speaking\"'), (3, '0.003*\"mother\" + 0.003*\"love\" + 0.003*\"car\"')]\n",
      "   Topic_0 Topic_1     Topic_2 Topic_3\n",
      "0     kids     dad       money  mother\n",
      "1    white     mom        case    love\n",
      "2    black    love    speaking     car\n",
      "3    money  father         war  father\n",
      "4     city  police  government   woman\n",
      "5  country    kids         job   money\n",
      "6     high     car     country    kids\n",
      "7    state   phone         000     job\n",
      "8     guys   money      mother   music\n",
      "9    party     kid        guys    book\n",
      "\n",
      "10 0.9\n",
      "[(0, '0.006*\"kids\" + 0.004*\"black\" + 0.004*\"white\"'), (1, '0.004*\"dad\" + 0.003*\"father\" + 0.003*\"love\"'), (2, '0.006*\"money\" + 0.003*\"case\" + 0.002*\"mother\"'), (3, '0.003*\"mother\" + 0.003*\"car\" + 0.003*\"love\"'), (4, '0.004*\"speaking\" + 0.003*\"country\" + 0.003*\"war\"')]\n",
      "   Topic_0 Topic_1     Topic_2 Topic_3     Topic_4\n",
      "0     kids     dad       money  mother    speaking\n",
      "1    black  father        case     car     country\n",
      "2    white    love      mother    love         war\n",
      "3     love     mom         job  father   president\n",
      "4  parents   phone        bank   woman        kids\n",
      "5     high   money  government    kids       money\n",
      "6    money     kid         fbi    girl       state\n",
      "7     city     car         god     mom      police\n",
      "8      god    kids         000   money  government\n",
      "9  chicken  looked    hospital    book         job\n",
      "\n",
      "10 0.9\n",
      "[(0, '0.006*\"kids\" + 0.004*\"black\" + 0.004*\"white\"'), (1, '0.004*\"dad\" + 0.003*\"father\" + 0.003*\"love\"'), (2, '0.003*\"money\" + 0.003*\"case\" + 0.003*\"mother\"'), (3, '0.004*\"mother\" + 0.003*\"love\" + 0.003*\"car\"'), (4, '0.004*\"war\" + 0.004*\"speaking\" + 0.003*\"kids\"'), (5, '0.006*\"money\" + 0.003*\"speaking\" + 0.003*\"000\"')]\n",
      "   Topic_0  Topic_1   Topic_2 Topic_3     Topic_4     Topic_5\n",
      "0     kids      dad     money  mother         war       money\n",
      "1    black   father      case    love    speaking    speaking\n",
      "2    white     love    mother     car        kids         000\n",
      "3  parents      mom       fbi  father     country     country\n",
      "4     high      car       job   woman        city     spanish\n",
      "5      god      kid  hospital    kids         job         job\n",
      "6   church     kids       god    girl      police   president\n",
      "7     city    phone      care   money       money     company\n",
      "8    money   looked      love    book  government  government\n",
      "9     love  parents     phone     mom   president       phone\n",
      "\n",
      "10 0.9\n",
      "[(0, '0.006*\"kids\" + 0.004*\"black\" + 0.004*\"white\"'), (1, '0.004*\"dad\" + 0.004*\"father\" + 0.003*\"love\"'), (2, '0.003*\"money\" + 0.003*\"mother\" + 0.002*\"chicken\"'), (3, '0.003*\"car\" + 0.003*\"love\" + 0.003*\"mother\"'), (4, '0.004*\"speaking\" + 0.004*\"war\" + 0.003*\"kids\"'), (5, '0.007*\"money\" + 0.004*\"speaking\" + 0.003*\"000\"'), (6, '0.005*\"case\" + 0.004*\"police\" + 0.004*\"court\"')]\n",
      "   Topic_0 Topic_1   Topic_2 Topic_3    Topic_4     Topic_5     Topic_6\n",
      "0     kids     dad     money     car   speaking       money        case\n",
      "1    black  father    mother    love        war    speaking      police\n",
      "2    white    love   chicken  mother       kids         000       court\n",
      "3  parents     mom      love   woman    country         job         fbi\n",
      "4     love     car       god  father      money     country  government\n",
      "5      mom  mother  hospital    girl       city     company         law\n",
      "6     high   money      care    kids  president     spanish        town\n",
      "7      god     kid     woman   money        job  government        drug\n",
      "8   mother   phone       mom    book        000        bank  department\n",
      "9   church  looked    father    guys       guys        guys       judge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 10\n",
    "max_df = 0.9\n",
    "new_models4 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models4.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.7\n",
      "[(0, '0.003*\"dad\" + 0.003*\"mom\" + 0.002*\"singing\"'), (1, '0.003*\"police\" + 0.003*\"speaking\" + 0.002*\"president\"'), (2, '0.002*\"mom\" + 0.002*\"dad\" + 0.002*\"church\"'), (3, '0.002*\"mom\" + 0.002*\"dad\" + 0.002*\"war\"')]\n",
      "     Topic_0     Topic_1     Topic_2   Topic_3\n",
      "0        dad      police         mom       mom\n",
      "1        mom    speaking         dad       dad\n",
      "2    singing   president      church       war\n",
      "3    brother  government    speaking   chicken\n",
      "4       song       party    students      iraq\n",
      "5       girl         law  government  speaking\n",
      "6  christmas        town       month   company\n",
      "7       town         mom        town      girl\n",
      "8      david       court        bank      food\n",
      "9       baby  republican     college  hospital\n",
      "\n",
      "5 0.7\n",
      "[(0, '0.002*\"mom\" + 0.002*\"dad\" + 0.002*\"singing\"'), (1, '0.003*\"police\" + 0.003*\"speaking\" + 0.003*\"president\"'), (2, '0.003*\"students\" + 0.002*\"church\" + 0.002*\"speaking\"'), (3, '0.002*\"mom\" + 0.002*\"dad\" + 0.002*\"war\"'), (4, '0.003*\"dad\" + 0.002*\"mom\" + 0.002*\"speaking\"')]\n",
      "   Topic_0     Topic_1     Topic_2   Topic_3    Topic_4\n",
      "0      mom      police    students       mom        dad\n",
      "1      dad    speaking      church       dad        mom\n",
      "2  singing   president    speaking       war   speaking\n",
      "3      war  government         mom     chris    chicken\n",
      "4     song       party     college  hospital       food\n",
      "5     town         law         dad     death      water\n",
      "6     girl  republican       david      iraq  christmas\n",
      "7    sarah        town        drug      girl    brother\n",
      "8    david       court  government   college   business\n",
      "9  brother      states       court        mr       town\n",
      "\n",
      "5 0.7\n",
      "[(0, '0.003*\"war\" + 0.002*\"singing\" + 0.002*\"mom\"'), (1, '0.003*\"police\" + 0.003*\"president\" + 0.003*\"speaking\"'), (2, '0.004*\"students\" + 0.002*\"schools\" + 0.002*\"college\"'), (3, '0.002*\"mom\" + 0.002*\"chris\" + 0.002*\"war\"'), (4, '0.002*\"speaking\" + 0.002*\"dad\" + 0.002*\"mom\"'), (5, '0.004*\"dad\" + 0.003*\"mom\" + 0.002*\"girl\"')]\n",
      "      Topic_0     Topic_1     Topic_2  Topic_3    Topic_4  Topic_5\n",
      "0         war      police    students      mom   speaking      dad\n",
      "1     singing   president     schools    chris        dad      mom\n",
      "2         mom    speaking     college      war        mom     girl\n",
      "3       david  government  government     iraq      water  brother\n",
      "4  government       party        bank  company       food     town\n",
      "5        girl  republican        drug      dad  christmas     baby\n",
      "6   president         law         mom    women    chicken       tv\n",
      "7        song       trump       class  chicken      santa   church\n",
      "8     brother       court    speaking     girl       town    girls\n",
      "9        hair      states      church      fed      month     died\n",
      "\n",
      "5 0.7\n",
      "[(0, '0.003*\"war\" + 0.002*\"singing\" + 0.002*\"song\"'), (1, '0.003*\"president\" + 0.003*\"police\" + 0.003*\"government\"'), (2, '0.003*\"students\" + 0.003*\"bank\" + 0.002*\"government\"'), (3, '0.002*\"chris\" + 0.002*\"war\" + 0.002*\"iraq\"'), (4, '0.002*\"water\" + 0.002*\"food\" + 0.002*\"chicken\"'), (5, '0.003*\"dad\" + 0.002*\"mom\" + 0.002*\"town\"'), (6, '0.005*\"dad\" + 0.005*\"mom\" + 0.004*\"speaking\"')]\n",
      "      Topic_0     Topic_1     Topic_2  Topic_3   Topic_4   Topic_5    Topic_6\n",
      "0         war   president    students    chris     water       dad        dad\n",
      "1     singing      police        bank      war      food       mom        mom\n",
      "2        song  government  government     iraq   chicken      town   speaking\n",
      "3  government       party      church      mom   company    police       girl\n",
      "4      donald  republican    speaking      mrs     women      girl  christmas\n",
      "5   president         law       month  chicken  business        tv    brother\n",
      "6       david      states        drug  college       eat    health     sister\n",
      "7     brother       trump     college    bobby      jobs  hospital      david\n",
      "8     america       court       court    women     table      baby      santa\n",
      "9       susan        vote         pay   police       dad   brother      girls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 5\n",
    "max_df = 0.7\n",
    "new_models5 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models5.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.7\n",
      "[(0, '0.004*\"dad\" + 0.003*\"mom\" + 0.002*\"police\"'), (1, '0.003*\"mom\" + 0.002*\"dad\" + 0.002*\"girl\"'), (2, '0.005*\"speaking\" + 0.005*\"war\" + 0.003*\"government\"'), (3, '0.002*\"president\" + 0.002*\"town\" + 0.002*\"business\"')]\n",
      "   Topic_0   Topic_1     Topic_2     Topic_3\n",
      "0      dad       mom    speaking   president\n",
      "1      mom       dad         war        town\n",
      "2   police      girl  government    business\n",
      "3     girl     david        iraq  government\n",
      "4  brother      song   president       party\n",
      "5    child   singing     spanish         pay\n",
      "6    death   brother      states  republican\n",
      "7     baby     women        town     company\n",
      "8    women   chicken      police        drug\n",
      "9      son  speaking      united        bank\n",
      "\n",
      "10 0.7\n",
      "[(0, '0.004*\"dad\" + 0.003*\"police\" + 0.002*\"mom\"'), (1, '0.003*\"mom\" + 0.002*\"dad\" + 0.002*\"chicken\"'), (2, '0.005*\"speaking\" + 0.005*\"war\" + 0.003*\"government\"'), (3, '0.002*\"government\" + 0.002*\"president\" + 0.002*\"business\"'), (4, '0.004*\"mom\" + 0.003*\"dad\" + 0.002*\"girl\"')]\n",
      "   Topic_0   Topic_1     Topic_2     Topic_3  Topic_4\n",
      "0      dad       mom    speaking  government      mom\n",
      "1   police       dad         war   president      dad\n",
      "2      mom   chicken  government    business     girl\n",
      "3     game  speaking   president        town    women\n",
      "4      gun     david        iraq        drug     baby\n",
      "5    death       gay     spanish         pay     song\n",
      "6     shot      john      police     company  brother\n",
      "7  brother   playing      states        bank      sex\n",
      "8      boy      food         law       party   sister\n",
      "9   church      dave        town       month  singing\n",
      "\n",
      "10 0.7\n",
      "[(0, '0.004*\"police\" + 0.003*\"dad\" + 0.002*\"mom\"'), (1, '0.002*\"mom\" + 0.002*\"chicken\" + 0.002*\"dad\"'), (2, '0.006*\"speaking\" + 0.006*\"war\" + 0.003*\"government\"'), (3, '0.003*\"drug\" + 0.003*\"business\" + 0.002*\"bank\"'), (4, '0.004*\"mom\" + 0.003*\"dad\" + 0.002*\"girl\"'), (5, '0.004*\"republican\" + 0.004*\"party\" + 0.004*\"president\"')]\n",
      "   Topic_0   Topic_1     Topic_2     Topic_3  Topic_4      Topic_5\n",
      "0   police       mom    speaking        drug      mom   republican\n",
      "1      dad   chicken         war    business      dad        party\n",
      "2      mom       dad  government        bank     girl    president\n",
      "3     game     david        iraq     company    women         vote\n",
      "4      gun  speaking     spanish  government     baby        trump\n",
      "5     shot       dog   president         pay  brother    democrats\n",
      "6      fbi      girl      states        town      sex    political\n",
      "7   prison       gay      police       month     song     campaign\n",
      "8  brother   playing      united        cars   sister  republicans\n",
      "9    crime      food        town         buy  singing     election\n",
      "\n",
      "10 0.7\n",
      "[(0, '0.004*\"dad\" + 0.003*\"mom\" + 0.003*\"police\"'), (1, '0.003*\"mom\" + 0.002*\"speaking\" + 0.002*\"dad\"'), (2, '0.006*\"war\" + 0.005*\"speaking\" + 0.004*\"government\"'), (3, '0.003*\"drug\" + 0.003*\"business\" + 0.003*\"bank\"'), (4, '0.004*\"mom\" + 0.003*\"dad\" + 0.002*\"girl\"'), (5, '0.005*\"republican\" + 0.005*\"party\" + 0.004*\"president\"'), (6, '0.003*\"police\" + 0.003*\"chicken\" + 0.002*\"spanish\"')]\n",
      "   Topic_0   Topic_1     Topic_2     Topic_3  Topic_4      Topic_5    Topic_6\n",
      "0      dad       mom         war        drug      mom   republican     police\n",
      "1      mom  speaking    speaking    business      dad        party    chicken\n",
      "2   police       dad  government        bank     girl    president    spanish\n",
      "3     game     david        iraq     company    women         vote   speaking\n",
      "4      gun      camp   president  government      sex        trump        dad\n",
      "5    death      dave      states         pay     song    democrats       town\n",
      "6     shot       gay    military       month     baby     campaign  christmas\n",
      "7  brother      girl      united   insurance  brother  republicans        mom\n",
      "8      boy      john      killed        cars   sister    political       girl\n",
      "9      son   playing   americans         buy  singing     election       food\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 10\n",
    "max_df = 0.7\n",
    "new_models6 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models6.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.65\n",
      "[(0, '0.003*\"party\" + 0.002*\"students\" + 0.002*\"republican\"'), (1, '0.006*\"speaking\" + 0.004*\"war\" + 0.003*\"police\"'), (2, '0.004*\"dad\" + 0.002*\"brother\" + 0.002*\"baby\"'), (3, '0.004*\"government\" + 0.003*\"company\" + 0.002*\"bank\"')]\n",
      "      Topic_0     Topic_1    Topic_2     Topic_3\n",
      "0       party    speaking        dad  government\n",
      "1    students         war    brother     company\n",
      "2  republican      police       baby        bank\n",
      "3   president   president  christmas       month\n",
      "4       women  government        bed         buy\n",
      "5      police     spanish       food   companies\n",
      "6     college       court        boy        jobs\n",
      "7    campaign         law      david        plan\n",
      "8       trump      states     sister   insurance\n",
      "9     singing        iraq    chicken     million\n",
      "\n",
      "15 0.65\n",
      "[(0, '0.004*\"party\" + 0.003*\"republican\" + 0.003*\"president\"'), (1, '0.005*\"speaking\" + 0.003*\"war\" + 0.003*\"government\"'), (2, '0.004*\"dad\" + 0.002*\"christmas\" + 0.002*\"brother\"'), (3, '0.004*\"government\" + 0.003*\"company\" + 0.003*\"bank\"'), (4, '0.003*\"speaking\" + 0.003*\"police\" + 0.002*\"hospital\"')]\n",
      "      Topic_0     Topic_1    Topic_2     Topic_3   Topic_4\n",
      "0       party    speaking        dad  government  speaking\n",
      "1  republican         war  christmas     company    police\n",
      "2   president  government    brother        bank  hospital\n",
      "3    students     spanish       baby       month       war\n",
      "4    campaign   president    chicken   companies       dad\n",
      "5        vote       court       food         buy     death\n",
      "6       trump      police     sister        plan      died\n",
      "7   political         law      david        jobs      body\n",
      "8     college      states      girls   insurance     women\n",
      "9       women      united        eat     million      shot\n",
      "\n",
      "15 0.65\n",
      "[(0, '0.003*\"students\" + 0.002*\"singing\" + 0.002*\"police\"'), (1, '0.005*\"speaking\" + 0.004*\"spanish\" + 0.003*\"court\"'), (2, '0.004*\"dad\" + 0.002*\"christmas\" + 0.002*\"chicken\"'), (3, '0.004*\"government\" + 0.004*\"company\" + 0.003*\"bank\"'), (4, '0.003*\"speaking\" + 0.003*\"hospital\" + 0.002*\"dad\"'), (5, '0.007*\"war\" + 0.004*\"iraq\" + 0.003*\"president\"')]\n",
      "     Topic_0      Topic_1    Topic_2     Topic_3   Topic_4     Topic_5\n",
      "0   students     speaking        dad  government  speaking         war\n",
      "1    singing      spanish  christmas     company  hospital        iraq\n",
      "2     police        court    chicken        bank       dad   president\n",
      "3      party    president       baby       month     death    speaking\n",
      "4    college       police    brother   companies    police  republican\n",
      "5      women   government       food         buy      body       party\n",
      "6      trump          law        eat   insurance      died  government\n",
      "7    sinatra       church      david        jobs      john         fbi\n",
      "8  president  immigration     sister        plan   brother      states\n",
      "9       song       border        boy     million    doctor  department\n",
      "\n",
      "15 0.65\n",
      "[(0, '0.003*\"students\" + 0.002*\"party\" + 0.002*\"college\"'), (1, '0.005*\"speaking\" + 0.004*\"spanish\" + 0.004*\"court\"'), (2, '0.003*\"dad\" + 0.002*\"christmas\" + 0.002*\"chicken\"'), (3, '0.004*\"government\" + 0.004*\"company\" + 0.003*\"bank\"'), (4, '0.002*\"hospital\" + 0.002*\"baby\" + 0.002*\"dad\"'), (5, '0.007*\"war\" + 0.004*\"iraq\" + 0.003*\"party\"'), (6, '0.006*\"dad\" + 0.003*\"speaking\" + 0.002*\"police\"')]\n",
      "     Topic_0      Topic_1    Topic_2     Topic_3   Topic_4     Topic_5  \\\n",
      "0   students     speaking        dad  government  hospital         war   \n",
      "1      party      spanish  christmas     company      baby        iraq   \n",
      "2    college        court    chicken        bank       dad       party   \n",
      "3    singing       police      david       month     water   president   \n",
      "4      women    president        dog   companies     women  republican   \n",
      "5   teachers   government       food         buy  speaking    speaking   \n",
      "6      trump          law        eat   insurance   college    campaign   \n",
      "7    sinatra  immigration    brother        plan      wall  government   \n",
      "8  president         drug      santa     million      body   political   \n",
      "9        bob        judge      water        jobs     child      states   \n",
      "\n",
      "    Topic_6  \n",
      "0       dad  \n",
      "1  speaking  \n",
      "2    police  \n",
      "3     death  \n",
      "4      game  \n",
      "5       bed  \n",
      "6   brother  \n",
      "7    sister  \n",
      "8     girls  \n",
      "9       boy  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okay so I think I like 6 topics from this min/max combo\n",
    "min_df = 15\n",
    "max_df = 0.65\n",
    "new_models7 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models7.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.65\n",
      "[(0, '0.006*\"speaking\" + 0.004*\"police\" + 0.003*\"war\"'), (1, '0.002*\"company\" + 0.002*\"dad\" + 0.002*\"women\"'), (2, '0.003*\"students\" + 0.002*\"president\" + 0.002*\"dad\"'), (3, '0.003*\"dad\" + 0.003*\"court\" + 0.002*\"party\"')]\n",
      "      Topic_0     Topic_1     Topic_2     Topic_3\n",
      "0    speaking     company    students         dad\n",
      "1      police         dad   president       court\n",
      "2         war       women         dad       party\n",
      "3         dad     brother     schools      police\n",
      "4     spanish         buy         bob  republican\n",
      "5     chicken        bank     college         gay\n",
      "6        iraq        baby       girls   president\n",
      "7       women   christmas       class  government\n",
      "8  government         bed       month        john\n",
      "9      states  government  government         law\n",
      "\n",
      "20 0.65\n",
      "[(0, '0.007*\"speaking\" + 0.004*\"war\" + 0.004*\"police\"'), (1, '0.002*\"company\" + 0.002*\"women\" + 0.002*\"dad\"'), (2, '0.003*\"students\" + 0.003*\"president\" + 0.002*\"dad\"'), (3, '0.004*\"dad\" + 0.003*\"court\" + 0.003*\"party\"'), (4, '0.002*\"christmas\" + 0.002*\"brother\" + 0.002*\"alex\"')]\n",
      "      Topic_0     Topic_1    Topic_2     Topic_3    Topic_4\n",
      "0    speaking     company   students         dad  christmas\n",
      "1         war       women  president       court    brother\n",
      "2      police         dad        dad       party       alex\n",
      "3        iraq        bank    schools         gay        dog\n",
      "4     spanish        baby        bob      police        dad\n",
      "5         dad         buy    college  republican      david\n",
      "6  government  government      girls  government     police\n",
      "7       chris     brother      class   president      water\n",
      "8     chicken         bed        war        john      santa\n",
      "9      states      sister      sarah       judge       bird\n",
      "\n",
      "20 0.65\n",
      "[(0, '0.009*\"speaking\" + 0.005*\"war\" + 0.005*\"police\"'), (1, '0.002*\"dad\" + 0.002*\"women\" + 0.002*\"brother\"'), (2, '0.004*\"students\" + 0.003*\"dad\" + 0.003*\"schools\"'), (3, '0.005*\"dad\" + 0.004*\"court\" + 0.002*\"gay\"'), (4, '0.002*\"dad\" + 0.002*\"david\" + 0.002*\"santa\"'), (5, '0.004*\"government\" + 0.003*\"president\" + 0.003*\"company\"')]\n",
      "      Topic_0    Topic_1    Topic_2  Topic_3    Topic_4     Topic_5\n",
      "0    speaking        dad   students      dad        dad  government\n",
      "1         war      women        dad    court      david   president\n",
      "2      police    brother    schools      gay      santa     company\n",
      "3     spanish       baby    college   church    brother  republican\n",
      "4        iraq        bed      girls   police        dog       party\n",
      "5         dad     sister  president     drug  christmas         law\n",
      "6     chicken  christmas        bob    judge       bird        vote\n",
      "7      arabic       body      class     john    animals         fbi\n",
      "8      states        sex      sarah      boy       alex       month\n",
      "9  government      voice   teachers  sinatra      water        bank\n",
      "\n",
      "20 0.65\n",
      "[(0, '0.009*\"speaking\" + 0.005*\"war\" + 0.005*\"police\"'), (1, '0.002*\"women\" + 0.002*\"sex\" + 0.002*\"dad\"'), (2, '0.004*\"students\" + 0.003*\"schools\" + 0.003*\"president\"'), (3, '0.005*\"dad\" + 0.004*\"gay\" + 0.004*\"court\"'), (4, '0.002*\"dog\" + 0.002*\"bird\" + 0.002*\"cat\"'), (5, '0.004*\"government\" + 0.004*\"president\" + 0.003*\"law\"'), (6, '0.004*\"dad\" + 0.003*\"christmas\" + 0.003*\"brother\"')]\n",
      "      Topic_0   Topic_1    Topic_2  Topic_3  Topic_4     Topic_5    Topic_6\n",
      "0    speaking     women   students      dad      dog  government        dad\n",
      "1         war       sex    schools      gay     bird   president  christmas\n",
      "2      police       dad  president    court      cat         law    brother\n",
      "3     spanish      road        bob   church  animals       party       baby\n",
      "4        iraq  japanese    college   police    david  republican       song\n",
      "5     chicken     drive        war     drug    water     company      child\n",
      "6         dad   college        dad  sinatra     food         fbi        boy\n",
      "7      arabic  building      sarah     john      dad        vote      girls\n",
      "8  government       bed   teachers    judge  brother       court     sister\n",
      "9      states     water      girls      sex   police       month       game\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_df = 20\n",
    "max_df = 0.65\n",
    "new_models8 = []\n",
    "for num in [4, 5, 6, 7]:\n",
    "    ldamodel, output = cluster_fns.new_model_fn(ep_df, 'text', num, min_df, max_df)\n",
    "    print(cluster_fns.make_topic_df(ldamodel))\n",
    "    new_models8.append((num, ldamodel))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[(0, 0.18767372),\n",
       "   (1, 0.24076308),\n",
       "   (2, 0.09844182),\n",
       "   (3, 0.18870538),\n",
       "   (4, 0.0587864),\n",
       "   (5, 0.22562958)]],\n",
       " 1: [[(0, 0.18563873),\n",
       "   (1, 0.29880965),\n",
       "   (2, 0.09997512),\n",
       "   (3, 0.15308584),\n",
       "   (4, 0.06434872),\n",
       "   (5, 0.19814199)]],\n",
       " 2: [[(0, 0.18271291),\n",
       "   (1, 0.3171178),\n",
       "   (2, 0.09323008),\n",
       "   (3, 0.13908318),\n",
       "   (4, 0.05060488),\n",
       "   (5, 0.21725118)]],\n",
       " 3: [[(0, 0.15722972),\n",
       "   (1, 0.31456214),\n",
       "   (2, 0.06289257),\n",
       "   (3, 0.15033694),\n",
       "   (4, 0.035542395),\n",
       "   (5, 0.27943623)]]}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = new_models7[2][1]\n",
    "output6 = topic_distribution(by_period, 'text', model6)\n",
    "output6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187674</td>\n",
       "      <td>0.240763</td>\n",
       "      <td>0.098442</td>\n",
       "      <td>0.188705</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>0.225630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185639</td>\n",
       "      <td>0.298810</td>\n",
       "      <td>0.099975</td>\n",
       "      <td>0.153086</td>\n",
       "      <td>0.064349</td>\n",
       "      <td>0.198142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.182713</td>\n",
       "      <td>0.317118</td>\n",
       "      <td>0.093230</td>\n",
       "      <td>0.139083</td>\n",
       "      <td>0.050605</td>\n",
       "      <td>0.217251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.157230</td>\n",
       "      <td>0.314562</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.150337</td>\n",
       "      <td>0.035542</td>\n",
       "      <td>0.279436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   period   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5\n",
       "0     0.0  0.187674  0.240763  0.098442  0.188705  0.058786  0.225630\n",
       "1     1.0  0.185639  0.298810  0.099975  0.153086  0.064349  0.198142\n",
       "2     2.0  0.182713  0.317118  0.093230  0.139083  0.050605  0.217251\n",
       "3     3.0  0.157230  0.314562  0.062893  0.150337  0.035542  0.279436"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_tops_df = pd.DataFrame(columns=['period', 'topic_0', 'topic_1',\n",
    "                                      'topic_2', 'topic_3', 'topic_4', 'topic_5'])\n",
    "for key in output6.keys():\n",
    "    apply_tops_df.loc[len(apply_tops_df)] = [key] + [x[1] for x in output6[key][0]]\n",
    "apply_tops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>topic_0</td>\n",
       "      <td>0.187674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>topic_0</td>\n",
       "      <td>0.185639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>topic_0</td>\n",
       "      <td>0.182713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>topic_0</td>\n",
       "      <td>0.157230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>topic_1</td>\n",
       "      <td>0.240763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   period variable     value\n",
       "0     0.0  topic_0  0.187674\n",
       "1     1.0  topic_0  0.185639\n",
       "2     2.0  topic_0  0.182713\n",
       "3     3.0  topic_0  0.157230\n",
       "4     0.0  topic_1  0.240763"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_6 = pd.melt(apply_tops_df, id_vars=['period'])\n",
    "melted_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-101bf1dc600541d5b17ed6d50308f353\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-101bf1dc600541d5b17ed6d50308f353\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e3219457253f85520174959cea08e595\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"variable\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"period\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"value\", \"title\": \"Percentage\"}}, \"title\": \"Topic Change Over Time Periods\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-e3219457253f85520174959cea08e595\": [{\"period\": 0.0, \"variable\": \"topic_0\", \"value\": 0.18767371773719788}, {\"period\": 1.0, \"variable\": \"topic_0\", \"value\": 0.18563872575759888}, {\"period\": 2.0, \"variable\": \"topic_0\", \"value\": 0.18271291255950928}, {\"period\": 3.0, \"variable\": \"topic_0\", \"value\": 0.1572297215461731}, {\"period\": 0.0, \"variable\": \"topic_1\", \"value\": 0.2407630831003189}, {\"period\": 1.0, \"variable\": \"topic_1\", \"value\": 0.29880964756011963}, {\"period\": 2.0, \"variable\": \"topic_1\", \"value\": 0.3171178102493286}, {\"period\": 3.0, \"variable\": \"topic_1\", \"value\": 0.3145621418952942}, {\"period\": 0.0, \"variable\": \"topic_2\", \"value\": 0.09844181686639786}, {\"period\": 1.0, \"variable\": \"topic_2\", \"value\": 0.0999751165509224}, {\"period\": 2.0, \"variable\": \"topic_2\", \"value\": 0.09323008358478546}, {\"period\": 3.0, \"variable\": \"topic_2\", \"value\": 0.06289257109165192}, {\"period\": 0.0, \"variable\": \"topic_3\", \"value\": 0.18870538473129272}, {\"period\": 1.0, \"variable\": \"topic_3\", \"value\": 0.1530858427286148}, {\"period\": 2.0, \"variable\": \"topic_3\", \"value\": 0.13908317685127258}, {\"period\": 3.0, \"variable\": \"topic_3\", \"value\": 0.15033693611621857}, {\"period\": 0.0, \"variable\": \"topic_4\", \"value\": 0.05878639966249466}, {\"period\": 1.0, \"variable\": \"topic_4\", \"value\": 0.0643487200140953}, {\"period\": 2.0, \"variable\": \"topic_4\", \"value\": 0.05060487985610962}, {\"period\": 3.0, \"variable\": \"topic_4\", \"value\": 0.03554239496588707}, {\"period\": 0.0, \"variable\": \"topic_5\", \"value\": 0.22562958300113678}, {\"period\": 1.0, \"variable\": \"topic_5\", \"value\": 0.19814199209213257}, {\"period\": 2.0, \"variable\": \"topic_5\", \"value\": 0.21725118160247803}, {\"period\": 3.0, \"variable\": \"topic_5\", \"value\": 0.27943623065948486}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops_over_time = alt.Chart(melted_6).mark_line().encode(\n",
    "    x='period',\n",
    "    y='value',\n",
    "    color='variable'\n",
    ")\n",
    "tops_over_time.encoding.y.title = 'Percentage'\n",
    "tops_over_time.title = 'Topic Change Over Time Periods'\n",
    "tops_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ac3bcd356dd04502b398e0a46af020f0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-ac3bcd356dd04502b398e0a46af020f0\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 12, \"titleFontSize\": 12}, \"title\": {\"fontSize\": 16}}, \"data\": {\"name\": \"data-e3219457253f85520174959cea08e595\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"variable\"}, \"order\": {\"type\": \"ordinal\", \"field\": \"variable\", \"sort\": \"ascending\"}, \"x\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Percentage\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"period\"}}, \"height\": 150, \"title\": \"Topic Change Over Time Periods\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-e3219457253f85520174959cea08e595\": [{\"period\": 0.0, \"variable\": \"topic_0\", \"value\": 0.18767371773719788}, {\"period\": 1.0, \"variable\": \"topic_0\", \"value\": 0.18563872575759888}, {\"period\": 2.0, \"variable\": \"topic_0\", \"value\": 0.18271291255950928}, {\"period\": 3.0, \"variable\": \"topic_0\", \"value\": 0.1572297215461731}, {\"period\": 0.0, \"variable\": \"topic_1\", \"value\": 0.2407630831003189}, {\"period\": 1.0, \"variable\": \"topic_1\", \"value\": 0.29880964756011963}, {\"period\": 2.0, \"variable\": \"topic_1\", \"value\": 0.3171178102493286}, {\"period\": 3.0, \"variable\": \"topic_1\", \"value\": 0.3145621418952942}, {\"period\": 0.0, \"variable\": \"topic_2\", \"value\": 0.09844181686639786}, {\"period\": 1.0, \"variable\": \"topic_2\", \"value\": 0.0999751165509224}, {\"period\": 2.0, \"variable\": \"topic_2\", \"value\": 0.09323008358478546}, {\"period\": 3.0, \"variable\": \"topic_2\", \"value\": 0.06289257109165192}, {\"period\": 0.0, \"variable\": \"topic_3\", \"value\": 0.18870538473129272}, {\"period\": 1.0, \"variable\": \"topic_3\", \"value\": 0.1530858427286148}, {\"period\": 2.0, \"variable\": \"topic_3\", \"value\": 0.13908317685127258}, {\"period\": 3.0, \"variable\": \"topic_3\", \"value\": 0.15033693611621857}, {\"period\": 0.0, \"variable\": \"topic_4\", \"value\": 0.05878639966249466}, {\"period\": 1.0, \"variable\": \"topic_4\", \"value\": 0.0643487200140953}, {\"period\": 2.0, \"variable\": \"topic_4\", \"value\": 0.05060487985610962}, {\"period\": 3.0, \"variable\": \"topic_4\", \"value\": 0.03554239496588707}, {\"period\": 0.0, \"variable\": \"topic_5\", \"value\": 0.22562958300113678}, {\"period\": 1.0, \"variable\": \"topic_5\", \"value\": 0.19814199209213257}, {\"period\": 2.0, \"variable\": \"topic_5\", \"value\": 0.21725118160247803}, {\"period\": 3.0, \"variable\": \"topic_5\", \"value\": 0.27943623065948486}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_tops_time = alt.Chart(melted_6).mark_bar().encode(\n",
    "    alt.X('sum(value):Q',\n",
    "        scale=alt.Scale(domain=[0, 1])\n",
    "    ),\n",
    "    y='period:O',\n",
    "    color='variable',\n",
    "    order=alt.Order(\n",
    "      # Sort the segments of the bars by this field\n",
    "      'variable:O',\n",
    "      sort='ascending'\n",
    "    )\n",
    ").properties(width=400, height=150).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12\n",
    ").configure_title(fontSize=16)\n",
    "stack_tops_time.encoding.x.title = 'Percentage'\n",
    "stack_tops_time.title = 'Topic Change Over Time Periods'\n",
    "stack_tops_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we interested in any of these?\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
